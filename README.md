# Äá»“ Ã¡n mÃ´n há»c CS221: AnglE-optimized Embeddings ğŸ“
<p align="center">
  <img src="assets/framework.png" alt="Overall Framework" width="600"/>
</p>

**Vá» chi tiáº¿t cÃ¡ch sá»­ dá»¥ng, má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c táº¡i ğŸ“˜ tÃ i liá»‡u nÃ y:** https://angle.readthedocs.io/en/latest/index.html

ğŸ“¢ **Train/Infer Powerful Sentence Embeddings with AnglE.**

CÃ³ thá»ƒ sá»­ dá»¥ng thÆ° viá»‡n Ä‘á»ƒ Ã¡p dá»¥ng vÃ o bÃ i toÃ¡n khÃ¡c 1 cÃ¡ch tiá»‡n lá»£i báº±ng cÃ¡ch táº£i thÃ´ng qua: https://pypi.org/project/angle-emb/ hoáº·c lá»‡nh pip install angle-emb

ThÆ° viá»‡n nÃ y tá»« paper: [AnglE: Angle-optimized Text Embeddings](https://arxiv.org/abs/2309.12871).

## âœ¨ Cáº¥u trÃºc thÆ° má»¥c

```
Angle_Embedding/
â”œâ”€â”€ .gitignore              # Danh sÃ¡ch file/thÆ° má»¥c bá»‹ loáº¡i khá»i git
â”œâ”€â”€ .python-version         # PhiÃªn báº£n Python sá»­ dá»¥ng cho dá»± Ã¡n
â”œâ”€â”€ .readthedocs.yaml       # Cáº¥u hÃ¬nh build tÃ i liá»‡u trÃªn ReadTheDocs
â”œâ”€â”€ notebook/  
â”œâ”€â”€ angle_emb/              # ThÆ° viá»‡n chÃ­nh: mÃ£ nguá»“n AnglE (model, trainer, loss, utils)
â”‚   â”œâ”€â”€ __init__.py         # Khá»Ÿi táº¡o package Python
â”‚   â”œâ”€â”€ angle.py            # Äá»‹nh nghÄ©a lá»›p AnglE vÃ  cÃ¡c chá»©c nÄƒng chÃ­nh
â”‚   â”œâ”€â”€ angle_trainer.py    # Module huáº¥n luyá»‡n mÃ´ hÃ¬nh AnglE
â”‚   â”œâ”€â”€ base.py             # Lá»›p cÆ¡ sá»Ÿ cho cÃ¡c mÃ´ hÃ¬nh embedding
â”‚   â”œâ”€â”€ evaluation.py       # ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng embedding (Spearman, Pearson, ...)
â”‚   â”œâ”€â”€ loss.py             # Äá»‹nh nghÄ©a cÃ¡c hÃ m loss (Angle, Contrastive, Espresso, ...)
â”‚   â”œâ”€â”€ utils.py            # CÃ¡c hÃ m tiá»‡n Ã­ch dÃ¹ng chung
â”‚   â”œâ”€â”€ version.py          # ThÃ´ng tin phiÃªn báº£n thÆ° viá»‡n
â”œâ”€â”€ assets/                 # TÃ i nguyÃªn bá»• sung (hÃ¬nh áº£nh, biá»ƒu Ä‘á»“, ...)
â”œâ”€â”€ docs/                   # TÃ i liá»‡u dá»± Ã¡n (Sphinx, hÆ°á»›ng dáº«n, ghi chÃº, cáº¥u hÃ¬nh)
â”‚   â”œâ”€â”€ conf.py             # Cáº¥u hÃ¬nh Sphinx
â”‚   â”œâ”€â”€ index.rst           # Trang chá»§ tÃ i liá»‡u
â”‚   â”œâ”€â”€ Makefile, make.bat  # Script build tÃ i liá»‡u
â”‚   â”œâ”€â”€ requirements.txt    # YÃªu cáº§u cÃ i Ä‘áº·t cho tÃ i liá»‡u
â”‚   â””â”€â”€ notes/              # CÃ¡c ghi chÃº, hÆ°á»›ng dáº«n chi tiáº¿t
â”œâ”€â”€ en_results/             # Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh tiáº¿ng Anh (json, bÃ¡o cÃ¡o)
â”‚   â””â”€â”€ UAE-Large-V1/       # Káº¿t quáº£ cho model UAE-Large-V1
â”œâ”€â”€ examples/               # VÃ­ dá»¥ sá»­ dá»¥ng, notebook, script huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡
â”‚   â”œâ”€â”€ Angle-ATEC.ipynb    # Notebook vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u ATEC
â”‚   â”œâ”€â”€ Angle-BQ.ipynb      # Notebook vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u BQ
â”‚   â”œâ”€â”€ Angle-LCQMC.ipynb   # Notebook vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u LCQMC
â”‚   â”œâ”€â”€ Angle-PAWSX.ipynb   # Notebook vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u PAWSX
â”‚   â”œâ”€â”€ multigpu_infer.py   # VÃ­ dá»¥ inference Ä‘a GPU
â”‚   â”œâ”€â”€ NLI/                # VÃ­ dá»¥ vá» Natural Language Inference
â”‚   â”‚   â”œâ”€â”€ SentEval/       # Bá»™ toolkit Ä‘Ã¡nh giÃ¡ embedding (SentEval)
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md   # HÆ°á»›ng dáº«n sá»­ dá»¥ng SentEval
â”‚   â”‚   â”‚   â”œâ”€â”€ setup.py    # CÃ i Ä‘áº·t SentEval
â”‚   â”‚   â”‚   â””â”€â”€ senteval/   # MÃ£ nguá»“n cÃ¡c task Ä‘Ã¡nh giÃ¡ (STS, SICK, probing, ...)
â”‚   â”‚   â”‚       â”œâ”€â”€ probing.py
â”‚   â”‚   â”‚       â”œâ”€â”€ sick.py
â”‚   â”‚   â”‚       â”œâ”€â”€ sts.py
â”‚   â”‚   â”‚       â”œâ”€â”€ engine.py
â”‚   â”‚   â”‚       â””â”€â”€ tools/
â”‚   â”‚   â”‚           â””â”€â”€ ranking.py
â”‚   â”‚   â”œâ”€â”€ eval_nli.py     # Script Ä‘Ã¡nh giÃ¡ NLI
â”‚   â”‚   â”œâ”€â”€ eval_ese_nli.py # Script Ä‘Ã¡nh giÃ¡ ESE NLI
â”‚   â”‚   â”œâ”€â”€ train_nli.py    # Script huáº¥n luyá»‡n NLI
â”‚   â”‚   â””â”€â”€ data/           # Script táº£i dá»¯ liá»‡u NLI
â”‚   â”‚       â””â”€â”€ download_data.sh
â”‚   â””â”€â”€ UAE/                # VÃ­ dá»¥ vá» Universal AnglE Embeddings
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ compute_scores.py # tÃ­nh Ä‘iá»ƒm
â”‚       â”œâ”€â”€ emb_model.py
â”‚       â”œâ”€â”€ run_eval_mteb.py # ÄÃ¡nh giÃ¡ trÃªn MTEB
â”‚       â””â”€â”€ train.py # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”œâ”€â”€ LICENSE                 # Giáº¥y phÃ©p sá»­ dá»¥ng mÃ£ nguá»“n (MIT)
â”œâ”€â”€ MIGRATION_GUIDE.md      # HÆ°á»›ng dáº«n nÃ¢ng cáº¥p phiÃªn báº£n má»›i nháº¥t
â”œâ”€â”€ pyproject.toml          # Cáº¥u hÃ¬nh build vÃ  metadata dá»± Ã¡n Python
â”œâ”€â”€ README.md               # Giá»›i thiá»‡u vá» Ä‘á»“ Ã¡n
â”œâ”€â”€ README_2DMSE.md         # TÃ i liá»‡u vá» 2D Matryoshka Sentence Embeddings
â”œâ”€â”€ README_ESE.md           # TÃ i liá»‡u vá» Espresso Sentence Embeddings
â”œâ”€â”€ README_zh.md            # TÃ i liá»‡u tiáº¿ng Trung
â”œâ”€â”€ requirements.txt        # YÃªu cáº§u cÃ i Ä‘áº·t Python cho dá»± Ã¡n
â”œâ”€â”€ ruff.toml               # Cáº¥u hÃ¬nh linting vá»›i ruff
â”œâ”€â”€ scripts/                # Script tiá»‡n Ã­ch, chuyá»ƒn Ä‘á»•i mÃ´ hÃ¬nh, xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â””â”€â”€ convert_to_sentence_transformer.py
â”œâ”€â”€ tests/                  # test thá»­ mÃ´ hÃ¬nh nhanh
```


**Backbones**:
- BERT-based models (BERT, RoBERTa, ModernBERT, etc.)
- LLM-based models (LLaMA, Mistral, Qwen, etc.)
- Bi-directional LLM-based models (LLaMA, Mistral, Qwen, OpenELMo, etc.. refer to: https://github.com/WhereIsAI/BiLLM)

**Training**:
- Single-GPU training
- Multi-GPU training



## ğŸ› ï¸ CÃ i Ä‘áº·t
### Sá»­ dá»¥ng Conda

```bash
git clone https://github.com/BPhucKHMT/Angle_Embedding.git
cd Angle_Embedding

# Táº¡o environment má»›i vá»›i Python 3.10
conda create -n angle python=3.10 -y

# KÃ­ch hoáº¡t environment
conda activate angle

pip install -e .
```


## ğŸš€ Thá»±c nghiá»‡m 

### STS Benchmark
#### A) CÃ¡ch 1: Sá»­ dá»¥ng pretrain models cá»§a tÃ¡c giáº£
Sá»­ dá»¥ng cÃ¡c model Ä‘Ã£ pretrain dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ nhanh
##### ğŸ¤— HF Pretrained Models

[AnglE NLI Sentence Embedding](https://huggingface.co/collections/SeanLee97/angle-nli-sentence-embeddings-6646de386099d0472c5e21c0)

##### English STS Results

| Model | STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |
| ------- |-------|-------|-------|-------|-------|--------------|-----------------|-------|
| [SeanLee97/angle-llama-7b-nli-20231027](https://huggingface.co/SeanLee97/angle-llama-7b-nli-20231027) | 78.68 | 90.58 | 85.49 | 89.56 | 86.91 |    88.92     |      81.18      | 85.90 |
| [SeanLee97/angle-llama-7b-nli-v2](https://huggingface.co/SeanLee97/angle-llama-7b-nli-v2) | 79.00 | 90.56 | 85.79 | 89.43 | 87.00 |    88.97     |      80.94      | 85.96 |
| [SeanLee97/angle-llama-13b-nli](https://huggingface.co/SeanLee97/angle-llama-13b-nli)  | 79.33 | 90.65 | 86.89 | 90.45 | 87.32 |    89.69     |      81.32       | **86.52** |
| [SeanLee97/angle-bert-base-uncased-nli-en-v1](https://huggingface.co/SeanLee97/angle-bert-base-uncased-nli-en-v1) | 75.09 | 85.56 | 80.66 | 86.44 | 82.47 | 85.16 | 81.23 | 82.37 |
---

**BERT**

```bash
python eval_nli.py \
--model_name_or_path SeanLee97/angle-bert-base-uncased-nli-en-v1 \
--pooling_strategy cls_avg
```
**LLM-based**

```bash
python eval_nli.py \
--model_name_or_path SeanLee97/angle-llama-7b-nli-v2 \
--pooling_strategy cls_avg
```

**BERT-BASE cho downstream task**

```bash
python eval_ese_nli.py \
  --model_name_or_path SeanLee97/angle-bert-base-uncased-nli-en-v1 \
  --pooling_strategy cls_avg \
  --mode test \
  --task_set transfer
```

#### B) CÃ¡ch 2: Huáº¥n luyá»‡n NLI cho STS Benchmark
##### 1. Chuáº©n bá»‹ gpu enviroment

##### 2. CÃ i Ä‘áº·t angle_emb

```bash
python -m pip install -U angle_emb
$ cd examples/NLI
```
##### 3. Táº£i xuá»‘ng vÃ  chuáº©n bá»‹ dá»¯ liá»‡u

###### 3.1 Táº£i xuá»‘ng dá»¯ liá»‡u multi_nli + snli:

cÃ¡c nli datasets sáº½ cÃ³ 3 cá»™t gá»“m cÃ¡c premise, hypothesis, label

```bash
$ cd data
$ sh download_data.sh
```

###### 3.2 Táº£i xuá»‘ng STS datasets

cÃ¡c sts datasets sáº½ cÃ³ 3 cá»™t tÆ°Æ¡ng á»©ng sentence1 , sentence2, score

```bash
$
$ cd SentEval/data/downstream
$ bash download_dataset.sh
```
###### 3.3 Chuáº©n hÃ³a láº¡i format
- Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a trong code thÃ nh dáº¡ng 'text1', 'text2', 'label'

##### 4. Training
###### 4.1 Bert
train:

```bash
python -m angle_emb.angle_trainer \
--train_name_or_path SeanLee97/all_nli_angle_format_a \
--save_dir ckpts/bert-base-nli-test \
--model_name_or_path google-bert/bert-base-uncased \
--pooling_strategy cls \
--maxlen 128 \
--ibn_w 30.0 \
--cosine_w 0.0 \
--angle_w 1.0 \
--angle_tau 20.0 \
--learning_rate 5e-5 \
--warmup_steps 50 \
--batch_size 128 \
--seed 42 \
--gradient_accumulation_steps 16 \
--epochs 10 \
--fp16 1
```
eval: 
```bash
 python eval_nli.py \
--model_name_or_path SeanLee97/bert-base-nli-test-0728 \
--pooling_strategy cls_avg
```

###### 4.2 LLM-based
train: 

```bash
python -m angle_emb.angle_trainer \
--model_name_or_path NousResearch/Llama-2-7b-hf \
--train_name_or_path SeanLee97/all_nli_angle_format_b \
--save_dir ckpts/NLI-STS-angle-llama-7b \
--query_prompt 'Summarize sentence "{text}" in one word:"' \
--is_llm 1 \
--apply_lora 1 \
--w2 35 --learning_rate 1e-4 --maxlen 50 \
--lora_r 32 --lora_alpha 32 --lora_dropout 0.1 \
--batch_size 120 --seed 42 --do_eval 0 --load_kbit 4 --gradient_accumulation_steps 4 --epochs 1
```

eval:

```bash
 python eval_nli.py \
--model_name_or_path NousResearch/Llama-2-7b-hf \
--lora_name_or_path SeanLee97/angle-llama-7b-nli \
--pooling_strategy last \
--is_llm 1
```

## Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ thá»±c nghiá»‡m

<p align="center">
  <img src="assets/benchmark1.png" alt="standard sts tasks" width="600"/>
   <br>
  <em>Standard STS tasks</em>
</p>



<p align="center">
  <img src="assets/benchmark2.png" alt="downstream sts tasks" width="600"/>
   <br>
  <em>Downstream classification tasks</em>
</p>

## ğŸ•¸ï¸ Custom Training (TrÃªn notebook demo)

### Notebook Train_AOE_vietnamese.ipynb

#### Backbone

Sá»­ dá»¥ng backbone phobert-base-v2 thay cho bert-base

#### Dá»¯ liá»‡u huáº¥n luyá»‡n

MÃ´ hÃ¬nh Ä‘Æ°á»£c train 2 láº§n thÃ´ng qua 2 bá»™ dataset:

**1) Dataset: anti-ai/ViNLI-SimCSE-supervised_v2**

Dataset gá»“m 3 cá»™t : Anchor( cÃ¢u gá»‘c), Entailment (cÃ¢u suy diá»…n), Contradiction(cÃ¢u mÃ¢u thuáº«n)

Sau khi Ä‘á»•i láº¡i format: 'query', 'pos', 'hard_neg'

**2) Dataset: doanhieung/stsbenchmark-sts-vi**

Dataset gá»“m 3 cá»™t: sentence1, sentence2, score

Sau khi Ä‘á»•i láº¡i format: 'text1', 'text2', 'label'

### Notebook AoE_Sentiment_Analysis.ipynb

So sÃ¡nh AoE Ä‘Ã£ pretrain trÃªn 2 datasets vá»›i cÃ¡c embedding PhoBert, sup-SimCSE-Vietnamese-phobert-base, dangvantuan/vietnamese-embedding trÃªn **task sentiment analysis**

#### Dá»¯ liá»‡u huáº¥n luyá»‡n

**Dataset: uitnlp/vietnamese_students_feedback** 

Dá»¯ liá»‡u gá»“m 2 cá»™t chÃ­nh: sentence vÃ  sentiment ( postive, negative, neutral)

Dá»¯ liá»‡u gá»“m 11426 dÃ²ng cho train vÃ  3166 dÃ²ng cho test

#### Äá»™ Ä‘o sá»­ dá»¥ng
 Accuracy, F1-score, 

## Báº£ng so sÃ¡nh giá»¯a cÃ¡c model trÃªn task sentiment analysis

<p align="center">
  <img src="assets/sentiment.png" alt="sentiment" width="600"/>
   <br>
  <em>Sentiment analysis </em>
</p>
