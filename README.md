# ğŸ“ Äá»“ Ã¡n mÃ´n há»c CS221: AnglE-optimized Embeddings

<div align="center">
  <img src="assets/framework.png" alt="Overall Framework" width="600"/>
  
  [![Documentation](https://img.shields.io/badge/docs-readthedocs-blue)](https://angle.readthedocs.io/en/latest/index.html)
  [![PyPI](https://img.shields.io/badge/PyPI-angle--emb-orange)](https://pypi.org/project/angle-emb/)
  [![Paper](https://img.shields.io/badge/Paper-arXiv-red)](https://arxiv.org/abs/2309.12871)
</div>

---

## ğŸ“– Giá»›i thiá»‡u

**Train/Infer Powerful Sentence Embeddings with AnglE.**

ThÆ° viá»‡n máº¡nh máº½ Ä‘á»ƒ huáº¥n luyá»‡n vÃ  suy luáº­n sentence embeddings dá»±a trÃªn phÆ°Æ¡ng phÃ¡p AnglE (Angle-optimized Text Embeddings). CÃ³ thá»ƒ tÃ­ch há»£p dá»… dÃ ng vÃ o cÃ¡c bÃ i toÃ¡n NLP khÃ¡c nhau.

**ğŸ“˜ TÃ i liá»‡u chi tiáº¿t:** https://angle.readthedocs.io/en/latest/index.html

**ğŸ“¦ CÃ i Ä‘áº·t nhanh Ä‘á»ƒ sá»­ dá»¥ng vÃ o 1 bÃ i toÃ¡n khÃ¡c:**
```bash
pip install angle-emb
```

**ğŸ“„ Paper gá»‘c:** [AnglE: Angle-optimized Text Embeddings](https://arxiv.org/abs/2309.12871)

---

## âœ¨ Cáº¥u trÃºc thÆ° má»¥c

```
Angle_Embedding/
â”‚
â”œâ”€â”€ ğŸ“„ .gitignore              # Danh sÃ¡ch file/thÆ° má»¥c bá»‹ loáº¡i khá»i git
â”œâ”€â”€ ğŸ .python-version         # PhiÃªn báº£n Python sá»­ dá»¥ng cho dá»± Ã¡n
â”œâ”€â”€ ğŸ“š .readthedocs.yaml       # Cáº¥u hÃ¬nh build tÃ i liá»‡u trÃªn ReadTheDocs
â”‚
â”œâ”€â”€ ğŸ““ notebook/               # Jupyter notebooks demo
â”‚   â”œâ”€â”€ AOE_Sentiment_Analysis.ipynb           # á»¨ng dá»¥ng vÃ o bÃ i toÃ¡n sentiment analysis
â”‚   â”œâ”€â”€ Train_AOE_vietnamese.ipynb         #pretrain trÃªn dataset tiáº¿ng viá»‡t
â”‚
â”œâ”€â”€ ğŸ”§ angle_emb/              # ThÆ° viá»‡n chÃ­nh: mÃ£ nguá»“n AnglE
â”‚   â”œâ”€â”€ __init__.py           # Khá»Ÿi táº¡o package Python
â”‚   â”œâ”€â”€ angle.py              # Äá»‹nh nghÄ©a lá»›p AnglE vÃ  cÃ¡c chá»©c nÄƒng chÃ­nh
â”‚   â”œâ”€â”€ angle_trainer.py      # Module huáº¥n luyá»‡n mÃ´ hÃ¬nh AnglE
â”‚   â”œâ”€â”€ base.py               # Lá»›p cÆ¡ sá»Ÿ cho cÃ¡c mÃ´ hÃ¬nh embedding
â”‚   â”œâ”€â”€ evaluation.py         # ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng embedding
â”‚   â”œâ”€â”€ loss.py               # Äá»‹nh nghÄ©a cÃ¡c hÃ m loss
â”‚   â”œâ”€â”€ utils.py              # CÃ¡c hÃ m tiá»‡n Ã­ch dÃ¹ng chung
â”‚   â””â”€â”€ version.py            # ThÃ´ng tin phiÃªn báº£n thÆ° viá»‡n
â”‚
â”œâ”€â”€ ğŸ–¼ï¸ assets/                 # TÃ i nguyÃªn bá»• sung (hÃ¬nh áº£nh, biá»ƒu Ä‘á»“)
â”‚
â”œâ”€â”€ ğŸ“– docs/                   # TÃ i liá»‡u dá»± Ã¡n
â”‚   â”œâ”€â”€ conf.py               # Cáº¥u hÃ¬nh Sphinx
â”‚   â”œâ”€â”€ index.rst             # Trang chá»§ tÃ i liá»‡u
â”‚   â”œâ”€â”€ Makefile, make.bat    # Script build tÃ i liá»‡u
â”‚   â”œâ”€â”€ requirements.txt      # YÃªu cáº§u cÃ i Ä‘áº·t cho tÃ i liá»‡u
â”‚   â””â”€â”€ notes/                # CÃ¡c ghi chÃº, hÆ°á»›ng dáº«n chi tiáº¿t
â”‚
â”œâ”€â”€ ğŸ“Š en_results/             # Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh tiáº¿ng Anh
â”‚   â””â”€â”€ UAE-Large-V1/         # Káº¿t quáº£ cho model UAE-Large-V1
â”‚
â”œâ”€â”€ ğŸ’¡ examples/               # VÃ­ dá»¥ sá»­ dá»¥ng, notebook, script
â”‚   â”œâ”€â”€ Angle-ATEC.ipynb      # Notebook vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u ATEC
â”‚   â”œâ”€â”€ Angle-BQ.ipynb        # Notebook vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u BQ
â”‚   â”œâ”€â”€ Angle-LCQMC.ipynb     # Notebook vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u LCQMC
â”‚   â”œâ”€â”€ Angle-PAWSX.ipynb     # Notebook vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u PAWSX
â”‚   â”œâ”€â”€ multigpu_infer.py     # VÃ­ dá»¥ inference Ä‘a GPU
â”‚   â”‚
â”‚   â”œâ”€â”€ NLI/                  # Natural Language Inference
â”‚   â”‚   â”œâ”€â”€ SentEval/         # Bá»™ toolkit Ä‘Ã¡nh giÃ¡ embedding
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”œâ”€â”€ setup.py
â”‚   â”‚   â”‚   â””â”€â”€ senteval/     # MÃ£ nguá»“n cÃ¡c task Ä‘Ã¡nh giÃ¡
â”‚   â”‚   â”‚       â”œâ”€â”€ probing.py
â”‚   â”‚   â”‚       â”œâ”€â”€ sick.py
â”‚   â”‚   â”‚       â”œâ”€â”€ sts.py
â”‚   â”‚   â”‚       â”œâ”€â”€ engine.py
â”‚   â”‚   â”‚       â””â”€â”€ tools/
â”‚   â”‚   â”‚           â””â”€â”€ ranking.py
â”‚   â”‚   â”œâ”€â”€ eval_nli.py       # Script Ä‘Ã¡nh giÃ¡ NLI
â”‚   â”‚   â”œâ”€â”€ eval_ese_nli.py   # Script Ä‘Ã¡nh giÃ¡ ESE NLI
â”‚   â”‚   â”œâ”€â”€ train_nli.py      # Script huáº¥n luyá»‡n NLI
â”‚   â”‚   â””â”€â”€ data/             # Script táº£i dá»¯ liá»‡u NLI
â”‚   â”‚       â””â”€â”€ download_data.sh
â”‚   â”‚
â”‚   â””â”€â”€ UAE/                  # Universal AnglE Embeddings
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ compute_scores.py # TÃ­nh Ä‘iá»ƒm
â”‚       â”œâ”€â”€ emb_model.py
â”‚       â”œâ”€â”€ run_eval_mteb.py  # ÄÃ¡nh giÃ¡ trÃªn MTEB
â”‚       â””â”€â”€ train.py          # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”‚
â”œâ”€â”€ ğŸ“œ LICENSE                 # Giáº¥y phÃ©p sá»­ dá»¥ng mÃ£ nguá»“n (MIT)
â”œâ”€â”€ ğŸ“ MIGRATION_GUIDE.md      # HÆ°á»›ng dáº«n nÃ¢ng cáº¥p phiÃªn báº£n
â”œâ”€â”€ âš™ï¸ pyproject.toml          # Cáº¥u hÃ¬nh build vÃ  metadata dá»± Ã¡n
â”œâ”€â”€ ğŸ“„ README.md               # Giá»›i thiá»‡u vá» Ä‘á»“ Ã¡n
â”œâ”€â”€ ğŸ“„ README_2DMSE.md         # TÃ i liá»‡u vá» 2D Matryoshka Sentence Embeddings
â”œâ”€â”€ ğŸ“„ README_ESE.md           # TÃ i liá»‡u vá» Espresso Sentence Embeddings
â”œâ”€â”€ ğŸ“„ README_zh.md            # TÃ i liá»‡u tiáº¿ng Trung
â”œâ”€â”€ ğŸ“‹ requirements.txt        # YÃªu cáº§u cÃ i Ä‘áº·t Python cho dá»± Ã¡n
â”œâ”€â”€ ğŸ” ruff.toml               # Cáº¥u hÃ¬nh linting vá»›i ruff
â”œâ”€â”€ ğŸ› ï¸ scripts/                # Script tiá»‡n Ã­ch, chuyá»ƒn Ä‘á»•i mÃ´ hÃ¬nh
â”‚   â””â”€â”€ convert_to_sentence_transformer.py
â””â”€â”€ ğŸ§ª tests/                  # Test thá»­ mÃ´ hÃ¬nh nhanh
```

---


## ğŸ› ï¸ CÃ i Ä‘áº·t

### Sá»­ dá»¥ng Conda

```bash
# Clone repository
git clone https://github.com/BPhucKHMT/Angle_Embedding.git
cd Angle_Embedding

# Táº¡o environment má»›i vá»›i Python 3.10
conda create -n angle python=3.10 -y

# KÃ­ch hoáº¡t environment
conda activate angle

# CÃ i Ä‘áº·t
pip install -e .
```

---

## ğŸš€ Thá»±c nghiá»‡m

### ğŸ“Š STS Benchmark

#### A) **CÃ¡ch 1: Sá»­ dá»¥ng pretrained models**

##### ğŸ¤— HF Pretrained Models

Tham kháº£o: [AnglE NLI Sentence Embedding Collection](https://huggingface.co/collections/SeanLee97/angle-nli-sentence-embeddings-6646de386099d0472c5e21c0)

##### ğŸ“ˆ English STS Results

| Model | STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness | Avg. |
|-------|-------|-------|-------|-------|-------|--------------|-----------------|------|
| [angle-llama-7b-nli-20231027](https://huggingface.co/SeanLee97/angle-llama-7b-nli-20231027) | 78.68 | 90.58 | 85.49 | 89.56 | 86.91 | 88.92 | 81.18 | 85.90 |
| [angle-llama-7b-nli-v2](https://huggingface.co/SeanLee97/angle-llama-7b-nli-v2) | 79.00 | 90.56 | 85.79 | 89.43 | 87.00 | 88.97 | 80.94 | 85.96 |
| [angle-llama-13b-nli](https://huggingface.co/SeanLee97/angle-llama-13b-nli) | 79.33 | 90.65 | 86.89 | 90.45 | 87.32 | 89.69 | 81.32 | **86.52** |
| [angle-bert-base-uncased-nli-en-v1](https://huggingface.co/SeanLee97/angle-bert-base-uncased-nli-en-v1) | 75.09 | 85.56 | 80.66 | 86.44 | 82.47 | 85.16 | 81.23 | 82.37 |

---

**ÄÃ¡nh giÃ¡ BERT:**

```bash
python eval_nli.py \
  --model_name_or_path SeanLee97/angle-bert-base-uncased-nli-en-v1 \
  --pooling_strategy cls_avg
```

**ÄÃ¡nh giÃ¡ LLM-based:**

```bash
python eval_nli.py \
  --model_name_or_path SeanLee97/angle-llama-7b-nli-v2 \
  --pooling_strategy cls_avg
```

**ÄÃ¡nh giÃ¡ BERT-BASE cho downstream task:**

```bash
python eval_ese_nli.py \
  --model_name_or_path SeanLee97/angle-bert-base-uncased-nli-en-v1 \
  --pooling_strategy cls_avg \
  --mode test \
  --task_set transfer
```

---

#### B) **CÃ¡ch 2: Huáº¥n luyá»‡n NLI cho STS Benchmark**

##### 1ï¸âƒ£ Chuáº©n bá»‹ GPU environment

##### 2ï¸âƒ£ CÃ i Ä‘áº·t angle_emb

```bash
python -m pip install -U angle_emb
cd examples/NLI
```

##### 3ï¸âƒ£ Táº£i xuá»‘ng vÃ  chuáº©n bá»‹ dá»¯ liá»‡u

**3.1 Táº£i xuá»‘ng dá»¯ liá»‡u multi_nli + snli:**

CÃ¡c NLI datasets sáº½ cÃ³ 3 cá»™t: `premise`, `hypothesis`, `label`

```bash
cd data
sh download_data.sh
```

**3.2 Táº£i xuá»‘ng STS datasets:**

CÃ¡c STS datasets sáº½ cÃ³ 3 cá»™t: `sentence1`, `sentence2`, `score`

```bash
cd SentEval/data/downstream
bash download_dataset.sh
```

**3.3 Chuáº©n hÃ³a láº¡i format:**

Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a trong code thÃ nh dáº¡ng: `'text1'`, `'text2'`, `'label'`

##### 4ï¸âƒ£ Training

**4.1 BERT**

Train:

```bash
python -m angle_emb.angle_trainer \
  --train_name_or_path SeanLee97/all_nli_angle_format_a \
  --save_dir ckpts/bert-base-nli-test \
  --model_name_or_path google-bert/bert-base-uncased \
  --pooling_strategy cls \
  --maxlen 128 \
  --ibn_w 30.0 \
  --cosine_w 0.0 \
  --angle_w 1.0 \
  --angle_tau 20.0 \
  --learning_rate 5e-5 \
  --warmup_steps 50 \
  --batch_size 128 \
  --seed 42 \
  --gradient_accumulation_steps 16 \
  --epochs 10 \
  --fp16 1
```

Eval:

```bash
python eval_nli.py \
  --model_name_or_path SeanLee97/bert-base-nli-test-0728 \
  --pooling_strategy cls_avg
```

**4.2 LLM-based**

Train:

```bash
python -m angle_emb.angle_trainer \
  --model_name_or_path NousResearch/Llama-2-7b-hf \
  --train_name_or_path SeanLee97/all_nli_angle_format_b \
  --save_dir ckpts/NLI-STS-angle-llama-7b \
  --query_prompt 'Summarize sentence "{text}" in one word:"' \
  --is_llm 1 \
  --apply_lora 1 \
  --w2 35 --learning_rate 1e-4 --maxlen 50 \
  --lora_r 32 --lora_alpha 32 --lora_dropout 0.1 \
  --batch_size 120 --seed 42 --do_eval 0 --load_kbit 4 \
  --gradient_accumulation_steps 4 --epochs 1
```

Eval:

```bash
python eval_nli.py \
  --model_name_or_path NousResearch/Llama-2-7b-hf \
  --lora_name_or_path SeanLee97/angle-llama-7b-nli \
  --pooling_strategy last \
  --is_llm 1
```

---

## ğŸ“Š Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ thá»±c nghiá»‡m

<div align="center">
  <img src="assets/benchmark1.png" alt="Standard STS tasks" width="600"/>
  <p><em>Standard STS tasks</em></p>
</div>

<div align="center">
  <img src="assets/benchmark2.png" alt="Downstream classification tasks" width="600"/>
  <p><em>Downstream classification tasks</em></p>
</div>

---

## ğŸ•¸ï¸ Custom Training (TrÃªn notebook demo)

### ğŸ““ Notebook: Train_AOE_vietnamese.ipynb

#### ğŸ”§ Backbone

Sá»­ dá»¥ng backbone **phobert-base-v2** thay cho bert-base

#### ğŸ“š Dá»¯ liá»‡u huáº¥n luyá»‡n

MÃ´ hÃ¬nh Ä‘Æ°á»£c train 2 láº§n thÃ´ng qua 2 bá»™ dataset:

**1) Dataset: anti-ai/ViNLI-SimCSE-supervised_v2**

- Dataset gá»“m 3 cá»™t: `Anchor` (cÃ¢u gá»‘c), `Entailment` (cÃ¢u suy diá»…n), `Contradiction` (cÃ¢u mÃ¢u thuáº«n)
- Sau khi Ä‘á»•i láº¡i format: `'query'`, `'pos'`, `'hard_neg'`

**2) Dataset: doanhieung/stsbenchmark-sts-vi**

- Dataset gá»“m 3 cá»™t: `sentence1`, `sentence2`, `score`
- Sau khi Ä‘á»•i láº¡i format: `'text1'`, `'text2'`, `'label'`

### ğŸ“  Äá»™ Ä‘o sá»­ dá»¥ng

- CÃ¡c Ä‘á»™ Ä‘o nhÆ° lÃºc paper test vá»›i bá»™ dá»¯ liá»‡u tiáº¿ng anh á»Ÿ trÃªn

---

### ğŸ““ Notebook: AoE_Sentiment_Analysis.ipynb

So sÃ¡nh AoE Ä‘Ã£ pretrain trÃªn 2 datasets vá»›i cÃ¡c embedding:
- PhoBert
- sup-SimCSE-Vietnamese-phobert-base
- dangvantuan/vietnamese-embedding

TrÃªn **task sentiment analysis**

#### ğŸ“š Dá»¯ liá»‡u huáº¥n luyá»‡n

**Dataset: uitnlp/vietnamese_students_feedback**

- Dá»¯ liá»‡u gá»“m 2 cá»™t chÃ­nh: `sentence` vÃ  `sentiment` (positive, negative, neutral)
- Dá»¯ liá»‡u gá»“m **11,426 dÃ²ng** cho train vÃ  **3,166 dÃ²ng** cho test

#### Model sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n loáº¡i

-á»¨ng dá»¥ng logistic regression cho má»i embedding

#### ğŸ“ Äá»™ Ä‘o sá»­ dá»¥ng

- Accuracy
- F1-score

---

## ğŸ† Báº£ng so sÃ¡nh giá»¯a cÃ¡c model trÃªn task sentiment analysis

<div align="center">
  <img src="assets/sentiment.png" alt="Sentiment Analysis Comparison" width="600"/>
  <p><em>Sentiment analysis comparison</em></p>
</div>

---

## ğŸ“ Citation

```bibtex
@article{li2023angle,
  title={AnglE-optimized Text Embeddings},
  author={Li, Xianming and Li, Jing},
  journal={arXiv preprint arXiv:2309.12871},
  year={2023}
}
```
